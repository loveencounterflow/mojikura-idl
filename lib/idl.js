// Generated by CoffeeScript 1.10.0
(function() {
  var CND, MKNCR, O, alert, badge, debug, echo, help, info, log, rpr, urge, warn, whisper,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  CND = require('cnd');

  rpr = CND.rpr;

  badge = 'MOJIKURA-IDL/IDL';

  log = CND.get_logger('plain', badge);

  info = CND.get_logger('info', badge);

  whisper = CND.get_logger('whisper', badge);

  alert = CND.get_logger('alert', badge);

  debug = CND.get_logger('debug', badge);

  warn = CND.get_logger('warn', badge);

  help = CND.get_logger('help', badge);

  urge = CND.get_logger('urge', badge);

  echo = CND.echo.bind(CND);

  MKNCR = require('mingkwai-ncr');

  O = require('./options');

  this._err = function(me, idx, message) {

    /* Format error message with colors and token hiliting. */
    var tokens_txt;
    tokens_txt = this._rpr_tokens(me, idx);
    throw new Error(message + " " + tokens_txt);
  };


  /* Parser settings contain lists of operators with symbolic names, arity and so on. */

  this._parser_settings = O.idl;

  this._new_ctx = function(source) {
    var R;
    R = {
      '~isa': 'MOJIKURA-IDL/ctx',
      source: source,
      idx: 0,
      settings: this._parser_settings,
      tokens: null,
      tokentree: null,
      diagram: null
    };
    return R;
  };

  this.tokenize = function(source) {
    return this._tokenize(this._new_ctx(source));
  };

  this._tokenize = function(me) {
    var R, chrs, i, idx, len, lexeme;
    R = [];
    chrs = MKNCR.chrs_from_text(me.source);
    for (idx = i = 0, len = chrs.length; i < len; idx = ++i) {
      lexeme = chrs[idx];
      R.push(this._new_token(me, lexeme, idx));
    }
    me.tokens = R;
    return R;
  };

  this._new_token = function(me, lexeme, idx) {
    var R, operator, type;
    type = this._type_of_lexeme(me, lexeme);
    lexeme = MKNCR.jzr_as_uchr(lexeme);

    /* `t` for 'type' */
    R = {
      '~isa': 'MOJIKURA-IDL/token',
      s: lexeme,
      idx: idx,
      t: type
    };
    switch (type) {
      case 'operator':
        operator = this._operator_from_lexeme(me, lexeme);
        R.a = operator.arity;
        R.n = operator.name;
    }
    return R;
  };

  this._isa_token = function(me, x) {
    return CND.isa(x, 'MOJIKURA-IDL/token');
  };

  this._rpr_tokens = function(me, error_idx) {
    var R, i, idx, len, ref, token;
    if (error_idx == null) {
      error_idx = null;
    }
    if (error_idx == null) {
      error_idx = me.idx;
    }
    R = [];
    ref = me.tokens;
    for (idx = i = 0, len = ref.length; i < len; idx = ++i) {
      token = ref[idx];
      R.push(idx === error_idx ? CND.red(" ✘ " + token.s + " ✘ ") : CND.white("" + token.s));
    }
    return CND.white("[ " + (R.join('')) + " ]");
  };

  this._operator_from_lexeme = function(me, lexeme) {
    var R;
    if ((R = me.settings.operators[lexeme]) == null) {
      throw new Error("unknown operator " + (rpr(lexeme)));
    }
    return R;
  };

  this._describe_lexeme = function(me, lexeme) {
    return MKNCR.describe(lexeme);
  };

  this._tags_from_lexeme = function(me, lexeme) {
    var ref;
    return (ref = (this._describe_lexeme(me, lexeme)).tag) != null ? ref : [];
  };

  this._lexeme_is_operator = function(me, lexeme) {
    return lexeme in me.settings.operators;
  };

  this._lexeme_is_component = function(me, lexeme) {
    return indexOf.call(this._tags_from_lexeme(me, lexeme), 'cjk') >= 0;
  };

  this._type_of_lexeme = function(me, lexeme) {
    if (this._lexeme_is_operator(me, lexeme)) {
      return 'operator';
    }
    if (this._lexeme_is_component(me, lexeme)) {
      return 'component';
    }
    return 'other';
  };

  this.parse = this.diagram_from_source = function(source) {
    return this._diagram_from_tokentree(this.tokentree_from_source(source));
  };

  this._diagram_from_tokentree = function(tokentree) {

    /* A 'diagram' is a 'lexeme tree', i.e. the simplified version of a token tree, minus all the
    additional data, leaving just nested lists of lexemes.
     */
    var token;
    if (this._isa_token(null, tokentree)) {
      return tokentree.s;
    }
    return (function() {
      var i, len, results;
      results = [];
      for (i = 0, len = tokentree.length; i < len; i++) {
        token = tokentree[i];
        results.push(this._diagram_from_tokentree(token));
      }
      return results;
    }).call(this);
  };

  this.tokentree_from_source = function(source) {
    return this._ctx_from_from_source(source);
  };

  this._ctx_from_from_source = function(source) {
    var R, me, ref, tokens, type;
    if ((type = CND.type_of(source)) !== 'text') {
      throw new Error("expected a text, got a " + type);
    }
    if (!(source.length > 0)) {
      throw new Error("IDL: empty text");
    }
    me = this._new_ctx(source);
    tokens = this._tokenize(me);
    R = this._get_tokentree(me);
    if (me.idx !== me.tokens.length) {
      this._err(me, me.idx, "IDL: extra token(s)");
    }
    if ((me.tokens.length === 1) && ((ref = (type = me.tokens[0].t)) === 'other' || ref === 'component')) {
      this._err(me, 0, "IDL: lone token of type " + (rpr(type)));
    }
    me.tokentree = R;
    return R;
  };

  this._get_tokentree = function(me, R) {
    var arity, count, i, ref, target, token, type;
    if (R == null) {
      R = null;
    }
    token = me.tokens[me.idx];
    if (token == null) {
      this._err(me, me.idx - 1, "IDL: premature end of source");
    }
    me.idx += +1;
    target = null;
    arity = null;
    switch (type = token.t) {
      case 'operator':
        arity = token.a;
        target = [token];
        for (count = i = 1, ref = arity; i <= ref; count = i += +1) {
          this._get_tokentree(me, target);
        }
        if (R != null) {
          R.push(target);
        } else {
          R = target;
        }
        break;
      case 'component':
        if (R != null) {
          R.push(token);
        } else {
          R = token;
        }
        break;
      default:
        this._err(me, me.idx - 1, "IDL: illegal token " + (rpr(token.s)) + " (type " + (rpr(type)) + ")");
    }
    return R;
  };

  this._tokentree_as_text = function(me, parse_tree) {
    var R, element, i, len;
    R = [];
    for (i = 0, len = parse_tree.length; i < len; i++) {
      element = parse_tree[i];
      if (this._isa_token(me, element)) {
        R.push(element.s);
      } else {
        R.push(this._tokentree_as_text(me, element));
      }
    }
    return R.join('');
  };

}).call(this);

//# sourceMappingURL=idl.js.map
